{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) ..\\opencv_contrib\\modules\\face\\src\\lbph_faces.cpp:362: error: (-210:Unsupported format or combination of formats) Empty training data was given. You'll need more than one sample to learn a model. in function 'cv::face::LBPH::train'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-38073db04cd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"labels.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trainner.yml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) ..\\opencv_contrib\\modules\\face\\src\\lbph_faces.cpp:362: error: (-210:Unsupported format or combination of formats) Empty training data was given. You'll need more than one sample to learn a model. in function 'cv::face::LBPH::train'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "BASE_DIR =Path().resolve()\n",
    "                          \n",
    "image_DIR =os.path.join(BASE_DIR, \"images\")\n",
    "face_cascade=cv2.CascadeClassifier('C:\\\\Users\\\\Sandipan\\\\project\\\\HAARCASCADE\\\\haarcascade_frontalface_default.xml')\n",
    "recognizer= cv2.face.LBPHFaceRecognizer_create()\n",
    "label_ids={}\n",
    "current_id=0\n",
    "y_labels =[]\n",
    "x_train= []\n",
    "                          \n",
    "                          \n",
    "for root, dirs , files in os.walk(image_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path= os.path.join(root,file)\n",
    "            label= os.path.basename(os.path.dirname(path)).lower()\n",
    "            print(label,path)\n",
    "            if not label in label_ids:\n",
    "                label_ids[label] = current_id\n",
    "                current_id += 1\n",
    "            \n",
    "            id_ = label_ids[label]\n",
    "            print(label_ids)\n",
    "            pil_image= Image.open(path).convert(\"L\")\n",
    "            image_array=np.array(pil_image,\"uint8\")\n",
    "            print(image_array)\n",
    "            faces = face_cascade.detectMultiScale(image_array, scaleFactor = 1.5, minNeighbors = 5)\n",
    "            for (x,y,w,h) in faces:\n",
    "                roi= image_array[y:y+h,x:x+w]\n",
    "                x_train.append(roi)\n",
    "                y_labels.append(id_)\n",
    "\n",
    "                \n",
    "print(y_labels)\n",
    "print(x_train)\n",
    "with open(\"labels.pickle\",'wb') as f:\n",
    "    pickle.dump(label_ids,f)\n",
    "recognizer.train(x_train,np.array(y_labels))\n",
    "recognizer.save(\"trainner.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225 160 182 182\n",
      "225 160 182 182\n",
      "224 161 182 182\n",
      "224 160 182 182\n",
      "222 160 182 182\n",
      "220 161 182 182\n",
      "222 160 182 182\n",
      "220 160 182 182\n",
      "222 160 182 182\n",
      "223 160 182 182\n",
      "224 159 182 182\n",
      "222 160 182 182\n",
      "224 159 182 182\n",
      "222 160 182 182\n",
      "222 160 182 182\n",
      "223 160 182 182\n",
      "224 159 182 182\n",
      "223 159 182 182\n",
      "223 160 182 182\n",
      "223 160 182 182\n",
      "224 161 182 182\n",
      "224 161 182 182\n",
      "225 160 182 182\n",
      "224 160 182 182\n",
      "223 160 182 182\n",
      "223 161 182 182\n",
      "219 159 182 182\n",
      "213 159 182 182\n",
      "2\n",
      "sandipan\n",
      "213 161 182 182\n",
      "213 160 182 182\n",
      "214 160 182 182\n",
      "214 160 182 182\n",
      "215 160 182 182\n",
      "213 161 182 182\n",
      "211 159 182 182\n",
      "2\n",
      "sandipan\n",
      "218 159 182 182\n",
      "230 154 182 182\n",
      "240 152 182 182\n",
      "251 148 182 182\n",
      "262 147 182 182\n",
      "264 147 182 182\n",
      "224 140 182 182\n",
      "2\n",
      "sandipan\n",
      "220 136 182 182\n",
      "2\n",
      "sandipan\n",
      "210 136 182 182\n",
      "201 137 182 182\n",
      "198 136 182 182\n",
      "194 137 182 182\n",
      "226 167 122 122\n",
      "2\n",
      "sandipan\n",
      "195 140 182 182\n",
      "196 137 182 182\n",
      "199 135 182 182\n",
      "202 138 182 182\n",
      "206 136 182 182\n",
      "2\n",
      "sandipan\n",
      "246 165 122 122\n",
      "2\n",
      "sandipan\n",
      "218 137 182 182\n",
      "216 134 182 182\n",
      "250 163 122 122\n",
      "2\n",
      "sandipan\n",
      "217 136 182 182\n",
      "219 136 182 182\n",
      "2\n",
      "sandipan\n",
      "254 162 122 122\n",
      "2\n",
      "sandipan\n",
      "219 135 182 182\n",
      "2\n",
      "sandipan\n",
      "252 164 122 122\n",
      "2\n",
      "sandipan\n",
      "219 136 182 182\n",
      "2\n",
      "sandipan\n",
      "252 164 122 122\n",
      "2\n",
      "sandipan\n",
      "222 134 182 182\n",
      "2\n",
      "sandipan\n",
      "250 161 122 122\n",
      "2\n",
      "sandipan\n",
      "250 164 122 122\n",
      "2\n",
      "sandipan\n",
      "250 162 122 122\n",
      "2\n",
      "sandipan\n",
      "246 164 122 122\n",
      "2\n",
      "sandipan\n",
      "213 140 182 182\n",
      "2\n",
      "sandipan\n",
      "245 164 122 122\n",
      "2\n",
      "sandipan\n",
      "245 166 122 122\n",
      "2\n",
      "sandipan\n",
      "246 164 122 122\n",
      "2\n",
      "sandipan\n",
      "244 164 122 122\n",
      "2\n",
      "sandipan\n",
      "246 166 122 122\n",
      "2\n",
      "sandipan\n",
      "213 140 182 182\n",
      "2\n",
      "sandipan\n",
      "245 164 122 122\n",
      "2\n",
      "sandipan\n",
      "246 165 122 122\n",
      "2\n",
      "sandipan\n",
      "254 165 122 122\n",
      "2\n",
      "sandipan\n",
      "223 138 182 182\n",
      "2\n",
      "sandipan\n",
      "262 166 122 122\n",
      "2\n",
      "sandipan\n",
      "283 164 122 122\n",
      "2\n",
      "sandipan\n",
      "284 166 122 122\n",
      "2\n",
      "sandipan\n",
      "238 119 182 182\n",
      "2\n",
      "sandipan\n",
      "219 126 182 182\n",
      "2\n",
      "sandipan\n",
      "195 124 182 182\n",
      "2\n",
      "sandipan\n",
      "178 123 182 182\n",
      "2\n",
      "sandipan\n",
      "154 124 182 182\n",
      "2\n",
      "sandipan\n",
      "133 126 182 182\n",
      "2\n",
      "sandipan\n",
      "122 126 182 182\n",
      "2\n",
      "sandipan\n",
      "109 122 182 182\n",
      "2\n",
      "sandipan\n",
      "100 121 182 182\n",
      "2\n",
      "sandipan\n",
      "94 121 182 182\n",
      "2\n",
      "sandipan\n",
      "94 129 182 182\n",
      "2\n",
      "sandipan\n",
      "95 133 182 182\n",
      "2\n",
      "sandipan\n",
      "99 133 182 182\n",
      "2\n",
      "sandipan\n",
      "97 132 182 182\n",
      "2\n",
      "sandipan\n",
      "98 137 182 182\n",
      "2\n",
      "sandipan\n",
      "99 140 182 182\n",
      "2\n",
      "sandipan\n",
      "98 143 182 182\n",
      "2\n",
      "sandipan\n",
      "98 143 182 182\n",
      "2\n",
      "sandipan\n",
      "101 143 182 182\n",
      "2\n",
      "sandipan\n",
      "98 143 182 182\n",
      "2\n",
      "sandipan\n",
      "102 142 182 182\n",
      "2\n",
      "sandipan\n",
      "105 142 182 182\n",
      "2\n",
      "sandipan\n",
      "105 145 182 182\n",
      "2\n",
      "sandipan\n",
      "110 147 182 182\n",
      "2\n",
      "sandipan\n",
      "110 149 182 182\n",
      "2\n",
      "sandipan\n",
      "109 147 182 182\n",
      "2\n",
      "sandipan\n",
      "108 150 182 182\n",
      "2\n",
      "sandipan\n",
      "109 147 182 182\n",
      "2\n",
      "sandipan\n",
      "110 148 182 182\n",
      "2\n",
      "sandipan\n",
      "103 149 182 182\n",
      "2\n",
      "sandipan\n",
      "104 150 182 182\n",
      "2\n",
      "sandipan\n",
      "102 150 182 182\n",
      "2\n",
      "sandipan\n",
      "102 150 182 182\n",
      "2\n",
      "sandipan\n",
      "102 150 182 182\n",
      "2\n",
      "sandipan\n",
      "102 150 182 182\n",
      "2\n",
      "sandipan\n",
      "102 150 182 182\n",
      "2\n",
      "sandipan\n",
      "103 149 182 182\n",
      "2\n",
      "sandipan\n",
      "112 152 182 182\n",
      "2\n",
      "sandipan\n",
      "118 153 182 182\n",
      "2\n",
      "sandipan\n",
      "118 153 182 182\n",
      "2\n",
      "sandipan\n",
      "119 153 182 182\n",
      "2\n",
      "sandipan\n",
      "118 152 182 182\n",
      "2\n",
      "sandipan\n",
      "116 153 182 182\n",
      "2\n",
      "sandipan\n",
      "118 152 182 182\n",
      "2\n",
      "sandipan\n",
      "117 153 182 182\n",
      "2\n",
      "sandipan\n",
      "118 151 182 182\n",
      "2\n",
      "sandipan\n",
      "119 147 182 182\n",
      "2\n",
      "sandipan\n",
      "121 146 182 182\n",
      "2\n",
      "sandipan\n",
      "127 140 182 182\n",
      "2\n",
      "sandipan\n",
      "112 143 182 182\n",
      "2\n",
      "sandipan\n",
      "116 144 182 182\n",
      "2\n",
      "sandipan\n",
      "115 147 182 182\n",
      "2\n",
      "sandipan\n",
      "118 145 182 182\n",
      "2\n",
      "sandipan\n",
      "117 146 182 182\n",
      "2\n",
      "sandipan\n",
      "120 146 182 182\n",
      "2\n",
      "sandipan\n",
      "120 147 182 182\n",
      "2\n",
      "sandipan\n",
      "123 147 182 182\n",
      "2\n",
      "sandipan\n",
      "122 148 182 182\n",
      "2\n",
      "sandipan\n",
      "126 147 182 182\n",
      "2\n",
      "sandipan\n",
      "137 143 182 182\n",
      "2\n",
      "sandipan\n",
      "129 140 182 182\n",
      "2\n",
      "sandipan\n",
      "118 140 182 182\n",
      "2\n",
      "sandipan\n",
      "119 141 182 182\n",
      "2\n",
      "sandipan\n",
      "120 146 182 182\n",
      "2\n",
      "sandipan\n",
      "152 154 182 182\n",
      "2\n",
      "sandipan\n",
      "234 162 182 182\n",
      "2\n",
      "sandipan\n",
      "231 157 182 182\n",
      "2\n",
      "sandipan\n",
      "226 163 182 182\n",
      "2\n",
      "sandipan\n",
      "228 159 182 182\n",
      "226 164 182 182\n",
      "226 160 182 182\n",
      "224 165 182 182\n",
      "224 164 182 182\n",
      "218 160 182 182\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "face_cascade=cv2.CascadeClassifier('C:\\\\Users\\\\Sandipan\\\\Desktop\\\\haarcascade\\\\haarcascade_frontalface_default.xml')\n",
    "recognizer= cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"trainner.yml\") \n",
    "lables= {\"person's name\" :1}\n",
    "with open(\"labels.pickle\",'rb') as f:\n",
    "    og_labels=pickle.load(f)\n",
    "    labels= {v:k for k,v in og_labels.items()}\n",
    "cap=cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.5, minNeighbors = 5)\n",
    "    for(x,y,w,h) in faces:\n",
    "        print(x,y,w,h)\n",
    "        roi_gray= gray[y:y+h,x:x+w] #[ycord1-height, ycord2-end]\n",
    "        roi_color= frame[y:y+h,x:x+w]\n",
    "        id_,conf= recognizer.predict(roi_gray)\n",
    "        if conf>=45 :#and conf<=85:\n",
    "            print(id_)\n",
    "            print(labels[id_])\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name = labels[id_]\n",
    "            color=(0,255,0)\n",
    "            stroke= 2\n",
    "            cv2.putText(frame,name,(x,y),font,1,color,stroke,cv2.LINE_AA)\n",
    "            \n",
    "        img_item =\"7.png\"\n",
    "        cv2.imwrite(img_item, roi_color)\n",
    "        color= (255,0,0)\n",
    "        stroke= 2\n",
    "        end_cord_x = x+w\n",
    "        end_cord_y = y+h\n",
    "        cv2.rectangle(frame,(x,y),(end_cord_x,end_cord_y),color,stroke)\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e4be05a5ea40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not iterable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
